apiVersion: v1
kind: ConfigMap
metadata:
  name: stable-diffusion-nginx-deployment-configmap
data:
  index_html: |
    <html>
    yx1111
    </html>
  # 修改nginx_onefile_yx.conf,然后复制进来即可
  nginx_conf: |
    worker_processes  auto;

    events {
        worker_connections 1024;
    }

    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /usr/local/openresty/nginx/logs/access.log  main;
        error_log /usr/local/openresty/nginx/logs/error.log error;
        client_max_body_size 0;

        map $http_upgrade $connection_upgrade {
            default upgrade;
            '' close;
        }

        include /etc/nginx/conf.d/default.conf;
    }
  # 修改default_onefile_yx.conf,然后复制进来即可
  default_conf: |
    server {
        listen 8080;
        root /usr/local/openresty/nginx/html;
        location /images/ {
        }
        location / {
            resolver kube-dns.kube-system.svc.cluster.local;  # use gke build-in Kube-DNS server
            set $target '';
            access_by_lua_file "sd.lua";
            proxy_pass http://$target;

            # modify by yx
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header Host $host;
            proxy_set_header Upgrade $http_upgrade;  # websocket
            proxy_set_header Connection "Upgrade";   # websocket
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            access_log off;
            client_max_body_size 100m;
            #
            proxy_set_header   Connection       "";   # 如果是supervisord的代理---logtail才能访问
            proxy_http_version 1.1;    # 如果是supervisord的代理---logtail才能访问
            proxy_connect_timeout              60s;
            proxy_send_timeout                 60s;
            proxy_read_timeout                 150s;
        }

        location /queue/join {
            resolver kube-dns.kube-system.svc.cluster.local;  # use gke build-in Kube-DNS server
            set $target '';
            access_by_lua_file "sd.lua";
            proxy_pass http://$target;
            
            # proxy_http_version 1.1;
            # proxy_set_header Upgrade $http_upgrade;
            # proxy_set_header Connection $connection_upgrade;
            # proxy_set_header Host $host;
            
            # modify by yx
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header Host $host;
            proxy_set_header Upgrade $http_upgrade;  # websocket
            proxy_set_header Connection "Upgrade";   # websocket
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            access_log off;
            client_max_body_size 100m;
            #
            proxy_set_header   Connection       "";   # 如果是supervisord的代理---logtail才能访问
            proxy_http_version 1.1;    # 如果是supervisord的代理---logtail才能访问
            proxy_connect_timeout              60s;
            proxy_send_timeout                 60s;
            proxy_read_timeout                 150s;
        }
    }
  # 修改sd_onefile_yx.lua,然后复制进来即可
  test_lua: |
    --  Copyright 2023 Google LLC
    -- 
    --  Licensed under the Apache License, Version 2.0 (the "License");
    --  you may not use this file except in compliance with the License.
    --  You may obtain a copy of the License at
    -- 
    --      http://www.apache.org/licenses/LICENSE-2.0
    -- 
    --  Unless required by applicable law or agreed to in writing, software
    --  distributed under the License is distributed on an "AS IS" BASIS,
    --  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    --  See the License for the specific language governing permissions and
    --  limitations under the License.
    local headers = ngx.req.get_headers()
    local key = headers["x-goog-authenticated-user-email"]
    -- print(key)

    if not key then
        if headers["user-agent"] == "GoogleHC/1.0" then
            ngx.log(ngx.INFO, "health check success!")
            ngx.say("health check success!")
            return ngx.exit(200)
        end
        ngx.log(ngx.ERR, "no iap user identity found")
        ngx.status = 400
        ngx.say("fail to fetch user identity!")
        return ngx.exit(400)
    end

    local redis = require "resty.redis"
    local red = redis:new()

    red:set_timeout(1000) -- 1 second
    local ok, err = red:connect("redis.private.domain", 6379)
    if not ok then
        ngx.log(ngx.ERR, "failed to connect to redis: ", err)
        ngx.status = 500
        ngx.say("failed to connect to redis!")
        return ngx.exit(500)
    end

    local secs = ngx.time()

    local lookup_res, err = red:hget(key, "target")
    print(lookup_res)

    if lookup_res == ngx.null then                
        local http = require "resty.http"
        local httpc = http.new()
        ngx.log(ngx.INFO, [[{"namespace": "default", "metadata": {"labels": {"user": "]] .. key .. [["}}}]])
        local sub_key = string.gsub(key, ":", ".")
        local final_uid = string.gsub(sub_key, "@", ".")
        local res, err = httpc:request_uri(
            -- 参考 https://agones.dev/site/docs/getting-started/create-fleet/#4-allocate-a-game-server-from-the-fleet
            "http://agones-allocator.agones-system.svc.cluster.local:443/gameserverallocation",
                {
                method = "POST",
                body = [[{"namespace": "default", "metadata": {"labels": {"user": "]] .. final_uid .. [["}}}]],
              }
        )

        local cjson = require "cjson"
        local resp_data = cjson.decode(res.body)
        local host = resp_data["address"]
        if host == nil then
            ngx.header.content_type = "text/html"
            ngx.say([[<h1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Too many users, Please try later! We are cooking for you!</h1><img src="images/coffee-clock.jpg" alt="Take a cup of coffea" />]])
            return
        end

        local sd_port = resp_data["ports"][2]["port"]
        local gs_port = resp_data["ports"][1]["port"]
        
        if string.match(host, "internal") ~= nil then
            local resolver = require "resty.dns.resolver"
            local dns = "169.254.169.254"

            local r, err = resolver:new{
                nameservers = {dns},
                retrans = 3,  -- 3 retransmissions on receive timeout
                timeout = 1000,  -- 1 sec
            }

            if not r then
                ngx.log(ngx.ERR, "failed to instantiate the resolver!")
                ngx.status = 400
                ngx.say("failed to instantiate the resolver!")
                return ngx.exit(400)
            end

            local answers, err = r:query(host)
            if not answers then
                ngx.log(ngx.ERR, "failed to query the DNS server!")
                ngx.status = 400
                ngx.say("failed to query the DNS server!")
                return ngx.exit(400)
            end

            if answers.errcode then
                ngx.log(ngx.ERR, "dns server returned error code!")
                ngx.status = 400
                ngx.say("dns server returned error code!")
                return ngx.exit(400)
            end

            for i, ans in ipairs(answers) do
                if ans.address then
                    ngx.log(ngx.INFO, ans.address)
                    host = ans.address
                end
            end
        end

        ngx.var.target = host .. ":" .. sd_port
        ngx.log(ngx.INFO, "set redis ", ngx.var.target)
    --     print("set redis ", ngx.var.target)

        ok, err = red:hset(key, "target", ngx.var.target, "port", host .. ":" .. gs_port, "lastaccess", secs)
        if not ok then
    --         print("fail to set redis key")
            ngx.log(ngx.ERR, "failed to hset: ", err)
            ngx.say("failed to hset: ", err)
            return
        end
    else
        ngx.var.target = lookup_res
        -- add by yx 判断ngx.var.target是否是有效地址,是否该pod已经被删除，如果是从redis中删除这个key, 因为pod是抢占式的，可能会被删除
        -- 后期这一部分改到定时任务中去做
        local http = require "resty.http"
        local httpc = http.new()
        httpc:set_timeout(1000*5) --毫秒
        local res, err = httpc:request_uri( 
            "http://" .. ngx.var.target .. "/fdafadew12_health_fajijiqjfajdsfs",
                {
                method = "GET",
              }
        )
        if not res then
            ngx.log(ngx.ERR, "Failed to request URI: ", err)
            ngx.status = 500
            ngx.say("抢占式sd服务器已经被删除, 请刷新页面重试!")
            --
            local ok, err = red:del(key) -- 删除redis中的key的全部信息
            --
            return ngx.exit(ngx.status)
        end
        if res.status == 200 then
            -- 什么都不做
            -- 调试
            -- ngx.log(ngx.INFO, "Received 200 status code: " .. ngx.var.target .. ", end", res.status)
            ngx.say("Failed to make the request." .. ngx.var.target .. res.body .. ", end")
            return
        else
            ngx.log(ngx.ERR, "Received non-200 status code: ", res.status)
            -- ngx.status = res.status
            -- ngx.say("Received non-200 status code.")
        end
        -- end add by yx
        ok, err = red:hset(key, "lastaccess", secs)
        if not ok then
    --         print("fail to set redis key")
            ngx.log(ngx.ERR, "failed to hset: ", err)
            ngx.say("failed to hset: ", err)
            return
        end
    end






---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stable-diffusion-nginx-deployment
  labels:
    app: stable-diffusion-nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: stable-diffusion-nginx
  template:
    metadata:
      labels:
        app: stable-diffusion-nginx
    spec:
      nodeSelector:
        cloud.google.com/gke-nodepool: default-pool  # 节点池选择
      containers:
        - name: stable-diffusion-nginx
          # image: k8s.gcr.io/nginx-slim:0.8
          image: openresty/openresty:1.21.4.1-0-focal
          # resources:
          #   limits: #
          #     cpu: 300m
          #     memory: 1Gi
          #   requests:
          #     cpu: 300m
          #     memory: 1Gi
          ports:
            - containerPort: 8080  # 暴露端口
          command: ["/bin/sh", "-c"]
          # sleep 86400  # 调试用
          # nginx -c /usr/local/openresty/nginx/conf/nginx.conf -g 'daemon off;'
          # /usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf -g 'daemon off;'
          # /usr/local/openresty/bin/openresty -c /usr/local/openresty/nginx/conf/nginx.conf -g 'daemon off;'
          args:
            - |
              opm get ledgetech/lua-resty-http &&
              opm get openresty/lua-resty-redis &&
              opm get openresty/lua-resty-dns &&
              /usr/local/openresty/bin/openresty -c /usr/local/openresty/nginx/conf/nginx.conf -g 'daemon off;'
          volumeMounts:
            - name: nginx-index-html
              mountPath: /etc/nginx/html/index.html
              subPath: index.html  # 必须和下面的volumes.configMap.items.path一样
            - name: nginx-conf
              mountPath: /usr/local/openresty/nginx/conf/nginx.conf
              subPath: nginx.conf
            - name: nginx-default-config
              mountPath: /etc/nginx/conf.d/default.conf
              subPath: default.conf
            - name: nginx-test-lua
              mountPath: /usr/local/openresty/nginx/sd.lua
              subPath: sd.lua
      volumes:
        - name: nginx-index-html
          configMap:
            name: stable-diffusion-nginx-deployment-configmap
            items:
              - key: index_html
                path: index.html
        - name: nginx-conf
          configMap:
            name: stable-diffusion-nginx-deployment-configmap
            items:
              - key: nginx_conf
                path: nginx.conf
        - name: nginx-default-config
          configMap:
            name: stable-diffusion-nginx-deployment-configmap
            items:
              - key: default_conf
                path: default.conf
        - name: nginx-test-lua
          configMap:
            name: stable-diffusion-nginx-deployment-configmap
            items:
              - key: test_lua
                path: sd.lua
