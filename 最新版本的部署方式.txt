https://github.com/GoogleCloudPlatform/stable-diffusion-on-gcp   最新的版本: 7e9bf448e6d7698f4d50a70083a07d1cf43269cf
这个版本我clone在0noyxgithub里面了
参考: /Users/yuanxiao/workspace/0noyxgithub/stable-diffusion-on-gcp


主要是 非 agones版本 和 agones 版本

两个版本都是跑在GKE上面的
非agones版本是不带认证的 和之前测试的类似 创建好容器之后使用LB来访问

agones版本是有认证的 
获得授权后用户完成iap验证就可以访问stable diffusion webui 
模型和插件都是共享目录挂载过去的 
agones版本有两个子版本 一个是带用户插件配置保留的 一个是不带用户插件配置保留的 




大概流程:
1. 用一台ecs来部署(安装特定版本的的gcloud和terraform)
    https://cloud.google.com/sdk/docs/install#linux
    https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli
    https://cloud.google.com/filestore/docs/mounting-fileshares?hl=zh-cn&_ga=2.186721135.-692251318.1691725083&_gac=1.58519896.1691725120.Cj0KCQjwldKmBhCCARIsAP-0rfwrt3hTG34UMpZ4dqKZeiL6ih-O0Aqv3hw3lIyqM7gWzXtFzQlTwHoaAhaEEALw_wcB#linux:-mount   将nfs挂载到ecs上
    -----
    sudo mount -o rw,intr 10.106.129.210:/vol1  /mnt
    -----
    ecs的ssh可以进入控制台，复制gcloud的命令进行ssh即可(输入谷歌账号的密码即可)：
    gcloud compute ssh --zone "us-central1-c" "sd-terraform-manage" --project "happyaigc"
    gcloud config set project happyaigc (输入谷歌账号的密码即可)

1.1 本地连接调试（不用esc的方式）----参考/Users/yuanxiao/workspace/0yxgithub/Stable-Diffusion-on-GCP/yx部署过程记录.txt 第四步
    
    获取gke集群的凭证
    source  ~/.zshrc_google_cloud  即可用gcloud命令
    ------------------------------------
    GKE_CLUSTER_NAME=tf-gen-gke-2b6bae98
    REGION=us-central1
    gcloud container clusters get-credentials ${GKE_CLUSTER_NAME} --region ${REGION}
    ------------------------------------
    f*b**1**
    ------------------------------------
    检测凭证生命周期
    ------------------------------------
    GKE_CLUSTER_NAME=tf-gen-gke-2b6bae98
    REGION=us-central1
    gcloud container clusters describe ${GKE_CLUSTER_NAME} \
        --region ${REGION} \
        --format "value(masterAuth.clusterCaCertificate)" \
        | base64 --decode \
        | openssl x509 -noout -dates
    ------------------------------------
    kubectl get fleet  # 校验


2. 用terraform-provision-infra/README_zh.md 的Agones 版本进行部署 （其实一步步来的话这里也有 Stable-Diffusion-UI-Agones/README_cn.md）

3. 准备域名sd.agones.playdayy.cn，覆盖上面terraform-provision-infra/main.tf的配置
    oauth_client_id 和 oauth_client_secret 看 Stable-Diffusion-UI-Agones/README_cn.md   “部署 IAP（identity awared proxy身份感知代理）”的部分
    -----main.tf----
    locals {
        project_id          = "happyaigc"
        oauth_client_id     = "972449351989-7nnen6jqnrd8im4ejcbj1p64fltpsurj.apps.googleusercontent.com"
        oauth_client_secret = "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"
        sd_webui_domain     = "sd.agones.playdayy.cn"
        region              = "us-central1"
        filestore_zone      = "us-central1-f" # Filestore location must be same region or zone with gke
        cluster_location    = "us-central1" # GKE Cluster location
        node_machine_type   = "custom-12-49152-ext"
        accelerator_type    = "nvidia-tesla-t4" # Available accelerator_type from gcloud compute accelerator-types list --format='csv(zone,name)'
        gke_num_nodes       = 1
    }
    -----main.tf----

4. 完成后通过https://console.cloud.google.com/security/iap?referrer=search&hl=zh-cn&project=happyaigc  添加用户

5. gcloud config set project happyaigc  (输入谷歌账号的密码即可)
   kubectl get all   # 获取所有资源概览
   ---
   kubectl get fleet
   kubectl get fleet -o yaml # 修改这个yaml，然后apply -f即可修改sd的镜像挂载等配置
   #####---参考terraform-provision-infra/modules/agones/cloud-build/variables.tf-----
   Stable-Diffusion-UI-Agones/agones-sidecar  yaml的第一个镜像就是这里build的
   Stable-Diffusion-UI-Agones/sd-webui/  yaml的第二个镜像是这里build的
   ####
   --------获取podyaml----
   kubectl get pod  sd-agones-fleet-klxgw-fj2lz -o yaml > haha.yaml


6. 调试 
   参考/Users/yuanxiao/workspace/0yxgithub/Stable-Diffusion-on-GCP/yx部署过程记录.txt 的【结束语】部分 
   ----进入ubuntu---
   kubectl  exec -it   -n default $(kubectl get pods  -n default  |grep ubuntu |awk '{print $1}' |awk NR==1)   /bin/bash
   ----进入fleet的agones的其中一个pod的gameserver的容器(pod描述命令: kubectl describe pod/sd-agones-fleet-lxpsk-9w2hm -n default)----
   kubectl  exec -it  -n default $(kubectl get pods  -n default  |grep sd-agones-fleet |awk '{print $1}' |awk NR==1)  -c agones-gameserver-sidecar   /bin/sh  # 这个gameserver好像没有用，只是agones自己启动的
   kubectl  exec -it  -n default $(kubectl get pods  -n default  |grep sd-agones-fleet |awk '{print $1}' |awk NR==1)  -c simple-game-server   /bin/sh   # 这里是agones真正的gameserver, 有AGONES_SDK_GRPC_PORT环境变量
   kubectl  exec -it  -n default $(kubectl get pods  -n default  |grep sd-agones-fleet |awk '{print $1}' |awk NR==1)  -c stable-diffusion-webui   /bin/sh   # 真正的sdwebui服务器
   ---
   重要理解(Stable-Diffusion-UI-Agones/nginx/sd.lua):
        sd.lua中： http://agones-allocator.agones-system.svc.cluster.local:443/gameserverallocation 这个api是agones的api，用来分配gameserver的，没有会自动创建gameserver这组pod的-------这个是最关键的-------;
        就算一个pod有多个容器，多个容器其实共享一个pod的ip地址，只是端口不一样, 所以 sd.lua 脚本中，只解析host，port不一样则可以区分访问的是fleet中的agones的两个容器的哪一个真正的的gameserver即可，这里stable-diffusion-webui和simple-game-server都算agones的容器， 但是开放端口不一样，agones只会检测固定pod的端口，所以可以根据固定端口检查出simple-game-server是真正的agones的入口gameserver，其他的容器只是其他的逻辑服，但是这些容器之间是平行的，没有上下级关系，只是通过不同的pod端口进行访问的区别而已。-------这个理解也是相当关键的-------;
        main.go中也就是simple-game-server中，判断7860是否能访问了，能访问就让simple-game-server处于ready状态，在gameserverallocation接口中，才会返回分配的服务器信息，这样访问sd也不会报错502了。------------ 这个也是相当关键的---------;
        sd.lua 中的sd_port 是从 Agones Allocator 获取到的 stable-diffusion-webui 容器的端口，而 gs_port 是获取到的 simple-game-server 容器的端口，
        sd.lua的作用是，根据游戏服务器地址是否为 "internal"，决定是否进行 DNS 查询，以获取内部地址的实际 IP 地址。
        将获取到的目标地址和端口信息存储到 Redis 中，以便下次查询， 设置 Nginx 变量 ngx.var.target 为获取的pod目标地址和sd端口，
        以便后续请求转发。
        pod内的多容器相互通信, 直接用127.0.0.1:容器端口通信即可
        
   

7. 后期清理： 一台ecs和静态ip， gke用destroy resource来清理即可, filestore的清理， artifacts的清理









其他----------------------------------------------------

agones安装完成后--------------------------------------------------------------------------------------------------------
https://agones.dev/site/docs/getting-started/create-gameserver/  入门, 客户端连接那一步可以在上面的调试ubuntu里面进行
################################################################################################
安装完成后，命名空间下有以下资源：
kubectl get deploy -n agones-system
NAME                READY   UP-TO-DATE   AVAILABLE   AGE
agones-allocator    3/3     3            3           3d
agones-controller   1/1     1            1           3d
agones-ping         2/2     2            2           3d

kubectl get po -n agones-system
NAME                                 READY   STATUS    RESTARTS   AGE
agones-allocator-554c79cffc-6dpzp    1/1     Running   0          3d
agones-allocator-554c79cffc-jlp5t    1/1     Running   0          3d
agones-allocator-554c79cffc-kbn5w    1/1     Running   0          3d
agones-controller-864dd7dbc4-2ghs8   1/1     Running   0          3d
agones-ping-77b7dc578c-9dfk7         1/1     Running   0          3d
agones-ping-77b7dc578c-hhvff         1/1     Running   0          3d

kubectl get svc -n agones-system
NAME                               TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)            AGE
agones-allocator                   LoadBalancer   172.16.157.137   47.105.53.1       443:30302/TCP      3d
agones-allocator-metrics-service   ClusterIP      172.16.238.137   <none>            8080/TCP           3d
agones-controller-service          ClusterIP      172.16.150.98    <none>            443/TCP,8080/TCP   3d
agones-ping-http-service           LoadBalancer   172.16.253.193   118.190.206.167   80:30770/TCP       3d
agones-ping-udp-service            LoadBalancer   172.16.10.63     47.104.240.179    50000:32691/UDP    3d

kubectl get gs # 获取agones游戏服务器-和kubectl get gameservers一样的效果
NAME                          STATE   ADDRESS      PORT   NODE                                                  AGE
sd-agones-fleet-klxgw-zj8f4   Ready   10.10.0.70   7961   gke-tf-gen-gke-2b6ba-nvidia-tesla-t4--acd027da-bvj0   14m
sd-agones-fleet-lxpsk-2xncq   Ready   10.10.0.60   7990   gke-tf-gen-gke-2b6ba-nvidia-tesla-t4--2fb69d9c-5p4x   29m

kubectl describe gameserver  # 看gameserver的状态
################################################################################################



kubectl get fleet -o yaml 的含义----------------------------------------------------

gpt4
################################################################################################
这段YAML文件是Kubernetes的资源配置文件，用于描述一个名为sd-agones-fleet的Fleet资源。Fleet是Agones项目中的一个资源类型，用于管理游戏服务器的集群。

在这个配置文件中，有两个image字段，它们分别对应两个不同的容器：

simple-game-server：这个容器的镜像是us-central1-docker.pkg.dev/happyaigc/sd-repository-2b6bae98/game-server:tf，它可能是一个游戏服务器的主程序。

stable-diffusion-webui：这个容器的镜像是us-central1-docker.pkg.dev/happyaigc/sd-repository-2b6bae98/sd-webui:tf，它可能是一个提供Web界面的服务。

这两个容器在同一个Pod中运行，它们可以共享网络和存储资源。这种模式通常用于将相关的服务组合在一起，例如一个Web服务和它的后端数据库。

在这个配置中，simple-game-server容器监听7654端口，stable-diffusion-webui容器监听7860端口。stable-diffusion-webui容器还挂载了一个名为stable-diffusion-storage的持久卷，用于存储模型和结果数据。

Fleet资源的spec.replicas字段设置为3，表示这个Fleet会管理3个这样的Pod。spec.scheduling字段设置为Packed，表示Agones会尽量将游戏服务器集中在尽可能少的节点上。spec.strategy字段设置为RollingUpdate，表示更新游戏服务器时会使用滚动更新策略，每次最多增加25%的Pod，最多停止25%的Pod。
################################################################################################

kubectl get pod  sd-agones-fleet-klxgw-fj2lz -o yaml 的含义----------------------------------------------------

gpt4-32k

################################################################################################
这个YAML清单定义了一个Kubernetes Pod，它是用于运行一个游戏服务器的Agones框架的一部分。Agones是由Google和Ubisoft联合开发的一个开源项目，用于在Kubernetes上运行、扩展和管理多人在线游戏。

这个Pod包含三个容器：

agones-gameserver-sidecar：这个容器是Agones SDK的一部分，它用于与Agones游戏服务器控制器进行通信和管理游戏生命周期。环境变量包含了游戏服务器的名称和Pod的命名空间。此外，还定义了一些特性开关（FEATURE_GATES）。

simple-game-server：这个容器运行实际的游戏服务器。它监听UDP端口7654，而此端口映射到主机端口7235。这个容器有一个健康检查端点/gshealthz在HTTP端口8080上。

stable-diffusion-webui：这个容器运行一个web界面，可能用于游戏的管理或监控。它监听TCP端口7860，而此端口映射到主机端口7541。这个容器需要一个NVIDIA GPU资源。

这个Pod被配置为优先调度到运行游戏服务器的节点上（根据标签agones.dev/role: gameserver）。这是通过Pod亲和性（podAffinity）来实现的。

这个Pod还具有一些特殊的配置，例如：

serviceAccount: agones-sdk：Pod使用的服务账户，可能用于与Kubernetes API的交互。
tolerations：允许Pod被调度到具有特定污点（taints）的节点上，例如具有GPU的节点。
volumes：Pod使用的存储卷，包括一个持久卷（用于存储模型和结果）和一个空的临时卷。
在status部分，你可以看到Pod的运行状态，包括每个容器的状态、IP地址、启动时间，以及Pod是否已准备好接受流量。
################################################################################################




kubectl get fleet -o yaml > fleet.yaml 
fleet.yaml 会生成两个pod类似下面的sd-agones-fleet-*-*
获取pod的yaml文件
kubectl get pod  sd-agones-fleet-klxgw-fj2lz > fleet_pod.yaml

我的问题有两个:
1. 为什么fleet.yaml会默认产生两个类似 sd-agones-fleet-*-*的pod 
2. 为什么fleet.yaml里面只有两个容器， 生成的fleet_pod.yaml里面有三个容器

############################################
当您在Kubernetes中创建一个Fleet对象时，它代表了一组Pod的控制器，该组Pod按照指定的副本数和模板创建和管理。您提供的Fleet YAML文件描述了一个Fleet对象，但似乎有一些配置导致了您观察到的现象。让我逐个回答您的问题：

    为什么会产生两个Pod？：在提供的Fleet YAML中，replicas: 1表示Fleet期望维持一个Pod副本。然而，实际产生了两个Pod的原因可能有很多，包括：
        容错机制：Kubernetes控制器，包括Fleet控制器，通常会使用容错机制，确保维持所需数量的Pod副本。如果一个Pod终止或启动失败，控制器可能会创建一个新的Pod，以满足所需状态。这可能解释了为什么您看到了两个Pod，尽管所需状态是一个。
        控制器更新：如果Fleet规范在初始创建后已经更新，Fleet控制器可能会检测到此更新，并根据更新的规范创建新的Pod。检查一下Fleet的副本数或其他相关字段是否有更新。
        手动干预：也有可能手动干预或与系统中其他组件的交互导致了额外的Pod创建。
    要进一步调查，您可能需要查看任何事件、日志或可能触发Fleet创建多个Pod的更新。

    当您创建 Fleet 对象时，生成的 fleet.yaml 文件中只定义了两个容器：simple-game-server 和 stable-diffusion-webui。然而，在生成的 fleet_pod.yaml 文件中出现了三个容器：agones-gameserver-sidecar、simple-game-server 和 stable-diffusion-webui。

agones-gameserver-sidecar是agones塞进去的，那个game server里没有跑进程---谷歌人员解答----
--
这可能是由于 Agones 游戏服务器 SDK 引入的影响。Agones 可能会自动添加一个辅助容器 agones-gameserver-sidecar 来管理游戏服务器实例的生命周期，从而导致生成的 Pod 定义中多出了一个容器。为了准确理解这个差异，您可以查阅 Agones 和 Fleet 控制器的文档，以及相关的注解和标签，以了解它们对 Pod 创建和管理的影响。
############################################
